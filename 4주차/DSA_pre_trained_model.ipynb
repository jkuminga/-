{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d0665e-46a1-460c-bc26-9a4520d5cb2d",
   "metadata": {},
   "source": [
    "# Pre_trained model + Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b8ba24-a8f6-440b-a5a3-814680ce3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5bf91ea-8127-486f-973e-a961ffb4b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV 파일 불러오기\n",
    "df= pd.read_csv(r\"C:\\Users\\DoHyeonjik\\GachonUniv\\3-2\\datasets\\DL\\DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0deabe08-b897-4fae-9db3-715318298924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "sitting                    480\n",
       "walkingTreadmillIncline    480\n",
       "jumping                    480\n",
       "rowing                     480\n",
       "cyclingVertical            480\n",
       "cyclingHorizontal          480\n",
       "crossTrainer               480\n",
       "stepper                    480\n",
       "runningTreadmill           480\n",
       "walkingTreadmillFlat       480\n",
       "standing                   480\n",
       "walkingLot                 480\n",
       "movingInElevator           480\n",
       "standingInElevatorStill    480\n",
       "decendingStairs            480\n",
       "ascendingStairs            480\n",
       "lyingRigh                  480\n",
       "lyingBack                  480\n",
       "basketBall                 480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#레이블 확인\n",
    "df['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d57c751d-29a2-4b65-b6fe-4328ffa16a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA_xacc_mean</th>\n",
       "      <th>RA_xacc_max</th>\n",
       "      <th>RA_xacc_min</th>\n",
       "      <th>RA_xacc_var</th>\n",
       "      <th>RA_xacc_std</th>\n",
       "      <th>RA_xacc_skew</th>\n",
       "      <th>RA_yacc_mean</th>\n",
       "      <th>RA_yacc_max</th>\n",
       "      <th>RA_yacc_min</th>\n",
       "      <th>RA_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>RA_ymag_min</th>\n",
       "      <th>RA_ymag_var</th>\n",
       "      <th>RA_ymag_std</th>\n",
       "      <th>RA_ymag_skew</th>\n",
       "      <th>RA_zmag_mean</th>\n",
       "      <th>RA_zmag_max</th>\n",
       "      <th>RA_zmag_min</th>\n",
       "      <th>RA_zmag_var</th>\n",
       "      <th>RA_zmag_std</th>\n",
       "      <th>RA_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679134</td>\n",
       "      <td>0.75930</td>\n",
       "      <td>0.58542</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>-0.415694</td>\n",
       "      <td>5.713088</td>\n",
       "      <td>5.8483</td>\n",
       "      <td>5.5956</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57428</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>-0.052190</td>\n",
       "      <td>-0.211136</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.24523</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>-1.153902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.644964</td>\n",
       "      <td>0.73158</td>\n",
       "      <td>0.53064</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.036508</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>5.795154</td>\n",
       "      <td>5.9546</td>\n",
       "      <td>5.6687</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57398</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.222740</td>\n",
       "      <td>-0.206431</td>\n",
       "      <td>-0.18054</td>\n",
       "      <td>-0.23624</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.458427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608212</td>\n",
       "      <td>0.67737</td>\n",
       "      <td>0.53546</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.025244</td>\n",
       "      <td>0.153302</td>\n",
       "      <td>5.833086</td>\n",
       "      <td>5.8918</td>\n",
       "      <td>5.7656</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57563</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>-0.221765</td>\n",
       "      <td>-0.205648</td>\n",
       "      <td>-0.18342</td>\n",
       "      <td>-0.22933</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.984915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.591138</td>\n",
       "      <td>0.71177</td>\n",
       "      <td>0.51524</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.036731</td>\n",
       "      <td>0.525019</td>\n",
       "      <td>5.863846</td>\n",
       "      <td>5.9645</td>\n",
       "      <td>5.7556</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57858</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.075011</td>\n",
       "      <td>-0.203739</td>\n",
       "      <td>-0.17999</td>\n",
       "      <td>-0.22958</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.185634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558168</td>\n",
       "      <td>0.67190</td>\n",
       "      <td>0.50535</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>1.076782</td>\n",
       "      <td>5.884745</td>\n",
       "      <td>5.9401</td>\n",
       "      <td>5.8384</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57996</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>-0.219440</td>\n",
       "      <td>-0.203684</td>\n",
       "      <td>-0.17904</td>\n",
       "      <td>-0.22924</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>-0.820907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.690373</td>\n",
       "      <td>30.46300</td>\n",
       "      <td>-4.90150</td>\n",
       "      <td>47.192912</td>\n",
       "      <td>6.869710</td>\n",
       "      <td>0.650080</td>\n",
       "      <td>2.187710</td>\n",
       "      <td>41.3410</td>\n",
       "      <td>-10.1410</td>\n",
       "      <td>81.350613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.89670</td>\n",
       "      <td>0.177217</td>\n",
       "      <td>0.420971</td>\n",
       "      <td>1.232819</td>\n",
       "      <td>-0.120793</td>\n",
       "      <td>0.58641</td>\n",
       "      <td>-0.61373</td>\n",
       "      <td>0.077901</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>0.611462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>6.477090</td>\n",
       "      <td>48.54700</td>\n",
       "      <td>-9.96820</td>\n",
       "      <td>44.135927</td>\n",
       "      <td>6.643488</td>\n",
       "      <td>1.675812</td>\n",
       "      <td>5.845459</td>\n",
       "      <td>33.7910</td>\n",
       "      <td>-48.3200</td>\n",
       "      <td>93.600217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.85305</td>\n",
       "      <td>0.158099</td>\n",
       "      <td>0.397617</td>\n",
       "      <td>1.560701</td>\n",
       "      <td>-0.133269</td>\n",
       "      <td>0.51707</td>\n",
       "      <td>-0.52776</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.241661</td>\n",
       "      <td>0.574120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>6.309986</td>\n",
       "      <td>27.29900</td>\n",
       "      <td>-8.43140</td>\n",
       "      <td>57.018917</td>\n",
       "      <td>7.551087</td>\n",
       "      <td>0.108921</td>\n",
       "      <td>6.342772</td>\n",
       "      <td>27.0570</td>\n",
       "      <td>-6.6706</td>\n",
       "      <td>51.945094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.83512</td>\n",
       "      <td>0.126188</td>\n",
       "      <td>0.355229</td>\n",
       "      <td>1.598340</td>\n",
       "      <td>-0.567238</td>\n",
       "      <td>-0.14483</td>\n",
       "      <td>-0.82409</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.152998</td>\n",
       "      <td>0.598665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>5.020496</td>\n",
       "      <td>30.16600</td>\n",
       "      <td>-20.25100</td>\n",
       "      <td>67.001032</td>\n",
       "      <td>8.185416</td>\n",
       "      <td>0.157547</td>\n",
       "      <td>5.824265</td>\n",
       "      <td>27.6300</td>\n",
       "      <td>-19.8830</td>\n",
       "      <td>63.100134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.87361</td>\n",
       "      <td>0.174494</td>\n",
       "      <td>0.417725</td>\n",
       "      <td>0.758435</td>\n",
       "      <td>0.211566</td>\n",
       "      <td>0.67931</td>\n",
       "      <td>-0.22328</td>\n",
       "      <td>0.060114</td>\n",
       "      <td>0.245181</td>\n",
       "      <td>0.316989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>4.293377</td>\n",
       "      <td>31.57000</td>\n",
       "      <td>-22.85700</td>\n",
       "      <td>105.947639</td>\n",
       "      <td>10.293087</td>\n",
       "      <td>0.223835</td>\n",
       "      <td>5.504619</td>\n",
       "      <td>27.3490</td>\n",
       "      <td>-13.7600</td>\n",
       "      <td>69.050466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.88818</td>\n",
       "      <td>0.144466</td>\n",
       "      <td>0.380087</td>\n",
       "      <td>0.359933</td>\n",
       "      <td>0.146602</td>\n",
       "      <td>0.62601</td>\n",
       "      <td>-0.28631</td>\n",
       "      <td>0.055074</td>\n",
       "      <td>0.234679</td>\n",
       "      <td>0.123701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RA_xacc_mean  RA_xacc_max  RA_xacc_min  RA_xacc_var  RA_xacc_std  \\\n",
       "0         0.679134      0.75930      0.58542     0.001546     0.039324   \n",
       "1         0.644964      0.73158      0.53064     0.001333     0.036508   \n",
       "2         0.608212      0.67737      0.53546     0.000637     0.025244   \n",
       "3         0.591138      0.71177      0.51524     0.001349     0.036731   \n",
       "4         0.558168      0.67190      0.50535     0.000626     0.025020   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "9115      8.690373     30.46300     -4.90150    47.192912     6.869710   \n",
       "9116      6.477090     48.54700     -9.96820    44.135927     6.643488   \n",
       "9117      6.309986     27.29900     -8.43140    57.018917     7.551087   \n",
       "9118      5.020496     30.16600    -20.25100    67.001032     8.185416   \n",
       "9119      4.293377     31.57000    -22.85700   105.947639    10.293087   \n",
       "\n",
       "      RA_xacc_skew  RA_yacc_mean  RA_yacc_max  RA_yacc_min  RA_yacc_var  ...  \\\n",
       "0        -0.415694      5.713088       5.8483       5.5956     0.003779  ...   \n",
       "1         0.410625      5.795154       5.9546       5.6687     0.001132  ...   \n",
       "2         0.153302      5.833086       5.8918       5.7656     0.000488  ...   \n",
       "3         0.525019      5.863846       5.9645       5.7556     0.001423  ...   \n",
       "4         1.076782      5.884745       5.9401       5.8384     0.000471  ...   \n",
       "...            ...           ...          ...          ...          ...  ...   \n",
       "9115      0.650080      2.187710      41.3410     -10.1410    81.350613  ...   \n",
       "9116      1.675812      5.845459      33.7910     -48.3200    93.600217  ...   \n",
       "9117      0.108921      6.342772      27.0570      -6.6706    51.945094  ...   \n",
       "9118      0.157547      5.824265      27.6300     -19.8830    63.100134  ...   \n",
       "9119      0.223835      5.504619      27.3490     -13.7600    69.050466  ...   \n",
       "\n",
       "      RA_ymag_min  RA_ymag_var  RA_ymag_std  RA_ymag_skew  RA_zmag_mean  \\\n",
       "0        -0.57428     0.000012     0.003401     -0.052190     -0.211136   \n",
       "1        -0.57398     0.000005     0.002216      0.222740     -0.206431   \n",
       "2        -0.57563     0.000004     0.001954     -0.221765     -0.205648   \n",
       "3        -0.57858     0.000007     0.002688      0.075011     -0.203739   \n",
       "4        -0.57996     0.000005     0.002278     -0.219440     -0.203684   \n",
       "...           ...          ...          ...           ...           ...   \n",
       "9115     -0.89670     0.177217     0.420971      1.232819     -0.120793   \n",
       "9116     -0.85305     0.158099     0.397617      1.560701     -0.133269   \n",
       "9117     -0.83512     0.126188     0.355229      1.598340     -0.567238   \n",
       "9118     -0.87361     0.174494     0.417725      0.758435      0.211566   \n",
       "9119     -0.88818     0.144466     0.380087      0.359933      0.146602   \n",
       "\n",
       "      RA_zmag_max  RA_zmag_min  RA_zmag_var  RA_zmag_std  RA_zmag_skew  \n",
       "0        -0.18401     -0.24523     0.000044     0.006638     -1.153902  \n",
       "1        -0.18054     -0.23624     0.000032     0.005660      0.458427  \n",
       "2        -0.18342     -0.22933     0.000024     0.004868     -0.984915  \n",
       "3        -0.17999     -0.22958     0.000026     0.005099      0.185634  \n",
       "4        -0.17904     -0.22924     0.000027     0.005175     -0.820907  \n",
       "...           ...          ...          ...          ...           ...  \n",
       "9115      0.58641     -0.61373     0.077901     0.279107      0.611462  \n",
       "9116      0.51707     -0.52776     0.058400     0.241661      0.574120  \n",
       "9117     -0.14483     -0.82409     0.023408     0.152998      0.598665  \n",
       "9118      0.67931     -0.22328     0.060114     0.245181      0.316989  \n",
       "9119      0.62601     -0.28631     0.055074     0.234679      0.123701  \n",
       "\n",
       "[9120 rows x 54 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RA, LA 나누기\n",
    "df_RA = df.filter(regex='RA_')\n",
    "df_LA = df.filter(regex='LA_')\n",
    "df_RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ced1bb89-8800-4863-b096-b7b4b292b666",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert activity, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 각 데이터에 레이블 삽입\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_RA\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m df_LA\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4931\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4925\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_duplicates=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4927\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.flags.allows_duplicate_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4928\u001b[0m     )\n\u001b[0;32m   4929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;129;01mand\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m   4930\u001b[0m     \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[1;32m-> 4931\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot insert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(loc):\n\u001b[0;32m   4933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc must be int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert activity, already exists"
     ]
    }
   ],
   "source": [
    "# 각 데이터에 레이블 삽입\n",
    "df_RA.insert(3, 'activity', df['activity'])\n",
    "df_LA.insert(3, 'activity', df['activity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "826a012e-d680-47ca-a92e-b76305ec7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RA_xacc_mean', 'RA_xacc_max', 'RA_xacc_min', 'activity', 'RA_xacc_var',\n",
      "       'RA_xacc_std', 'RA_xacc_skew', 'RA_yacc_mean', 'RA_yacc_max',\n",
      "       'RA_yacc_min', 'RA_yacc_var', 'RA_yacc_std', 'RA_yacc_skew',\n",
      "       'RA_zacc_mean', 'RA_zacc_max', 'RA_zacc_min', 'RA_zacc_var',\n",
      "       'RA_zacc_std', 'RA_zacc_skew', 'RA_xgyro_mean', 'RA_xgyro_max',\n",
      "       'RA_xgyro_min', 'RA_xgyro_var', 'RA_xgyro_std', 'RA_xgyro_skew',\n",
      "       'RA_ygyro_mean', 'RA_ygyro_max', 'RA_ygyro_min', 'RA_ygyro_var',\n",
      "       'RA_ygyro_std', 'RA_ygyro_skew', 'RA_zgyro_mean', 'RA_zgyro_max',\n",
      "       'RA_zgyro_min', 'RA_zgyro_var', 'RA_zgyro_std', 'RA_zgyro_skew',\n",
      "       'RA_xmag_mean', 'RA_xmag_max', 'RA_xmag_min', 'RA_xmag_var',\n",
      "       'RA_xmag_std', 'RA_xmag_skew', 'RA_ymag_mean', 'RA_ymag_max',\n",
      "       'RA_ymag_min', 'RA_ymag_var', 'RA_ymag_std', 'RA_ymag_skew',\n",
      "       'RA_zmag_mean', 'RA_zmag_max', 'RA_zmag_min', 'RA_zmag_var',\n",
      "       'RA_zmag_std', 'RA_zmag_skew'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\TempFolder\\ipykernel_23624\\2440497406.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RA['activity'] = label_encoder.fit_transform(df_RA['activity'])\n",
      "C:\\TempFolder\\ipykernel_23624\\2440497406.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_LA['activity'] = label_encoder.fit_transform(df_LA['activity'])\n"
     ]
    }
   ],
   "source": [
    "# 레이블(activity)를 문자열에서 숫자로 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_RA['activity'] = label_encoder.fit_transform(df_RA['activity'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_LA['activity'] = label_encoder.fit_transform(df_LA['activity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9245e1a2-2430-40d8-99b3-7edbb60d3daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "12    480\n",
       "18    480\n",
       "6     480\n",
       "10    480\n",
       "4     480\n",
       "3     480\n",
       "2     480\n",
       "15    480\n",
       "11    480\n",
       "17    480\n",
       "13    480\n",
       "16    480\n",
       "9     480\n",
       "14    480\n",
       "5     480\n",
       "0     480\n",
       "8     480\n",
       "7     480\n",
       "1     480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RA['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dc0303-f356-474a-a769-94c50cdbc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 분리: RA\n",
    "df_RA_Label = df_RA['activity']\n",
    "df_RA_data = df_RA.drop('activity', axis=1)\n",
    "# print(df_RA_Label)\n",
    "# print(df_RA_data)\n",
    "\n",
    "#레이블 분리 : LA\n",
    "df_LA_Label = df_LA['activity']\n",
    "df_LA_data = df_LA.drop('activity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43219ceb-1b74-4373-81d2-172d66c8c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata와 testdata로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_RA, x_test_RA, y_train_RA, y_test_RA = train_test_split(df_RA_data, df_RA_Label, test_size=0.25, random_state=21)\n",
    "x_train_LA, x_test_LA, y_train_LA, y_test_LA = train_test_split(df_LA_data, df_LA_Label, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a027bb7e-003b-4a95-91b3-4076a9d7d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6840, 54)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_RA.shape\n",
    "x_train_LA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "034631c1-38cf-4888-96bd-3e3fccdf66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()  # 빈 리스트를 생성하여 시퀀스 데이터와 레이블을 담을 공간을 만듦\n",
    "    for i in range(len(sequences)):  # 전체 시퀀스 데이터를 순회\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps  # 현재 인덱스(i)에서 n_steps만큼 떨어진 시퀀스의 끝을 계산\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):  # 시퀀스 끝이 데이터의 범위를 넘어서는지 확인\n",
    "            break  # 범위를 넘으면 루프 종료\n",
    "        # gather input (X) and output parts (y)\n",
    "        seq_x = sequences[i:end_ix, :-1]  # 입력 데이터 (특징 데이터)\n",
    "        seq_y_values = sequences[i:end_ix, -1]  # 시퀀스 동안의 출력 데이터 (레이블들)\n",
    "            \n",
    "        # 가장 빈번하게 나온 레이블 찾기\n",
    "        most_common_label = Counter(seq_y_values).most_common(1)[0][0]\n",
    "        if i ==0: print(most_common_label)\n",
    "        \n",
    "        X.append(seq_x)  # 입력 데이터 추가\n",
    "        y.append(most_common_label)  # 가장 많이 나온 레이블 추가\n",
    "    \n",
    "    return np.array(X), np.array(y)  # 리스트를 numpy 배열로 변환하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d4503fa-478f-4ce8-a2d1-7de57d5fe58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6840, 55)\n"
     ]
    }
   ],
   "source": [
    "#Merge train and test x/y data to apply sequence transformation function\n",
    "#훈련 데이터와 테스트 데이터의 레이블과 데이터를 병합 -> 시퀀스 변형을 위해서\n",
    "y_train_array_RA = np.array(y_train_RA) #RA의 훈련 레이블을 넘파이로 바꾸고\n",
    "train_set_RA = np.c_[x_train_RA, y_train_array_RA] #RA의 훈련데이터와 훈련레이블을 병합\n",
    "y_train_array_LA = np.array(y_train_LA) #LA의 훈련 레이블을 넘파이로 바꾸고\n",
    "train_set_LA = np.c_[x_train_LA, y_train_array_LA] #LA의 훈련데이터와 훈련레이블을 병합\n",
    "print(train_set_RA.shape)\n",
    "\n",
    "y_test_array_RA = np.array(y_test_RA) #RA의 테스트 레이블을 넘파이로 바꾸고\n",
    "test_set_RA = np.c_[x_test_RA, y_test_array_RA] #RA의 테스트데이터와 테스트레이블을 병합\n",
    "y_test_array_LA = np.array(y_test_LA) #LA의 테스트 레이블을 넘파이로 바꾸고\n",
    "test_set_LA = np.c_[x_test_LA, y_test_array_LA] #LA의 테스트데이터와 테스트레이블을 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80086f86-87e9-443d-9335-9e41f29ed304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "(6838, 3, 54) (6838,)\n",
      "7.0\n",
      "(2278, 3, 54) (2278,)\n",
      "9.0\n",
      "(6838, 3, 54) (6838,)\n",
      "7.0\n",
      "(2278, 3, 54) (2278,)\n"
     ]
    }
   ],
   "source": [
    "#split_sequence 적용\n",
    "n_step = 3 \n",
    "\n",
    "x_train_seq_RA, y_train_seq_RA = split_sequences(train_set_RA, n_step) # RA 훈련 데이터\n",
    "print(x_train_seq_RA.shape, y_train_seq_RA.shape)\n",
    "\n",
    "x_test_seq_RA, y_test_seq_RA = split_sequences(test_set_RA, n_step) # RA 훈련 레이블\n",
    "print(x_test_seq_RA.shape, y_test_seq_RA.shape)\n",
    "\n",
    "x_train_seq_LA, y_train_seq_LA = split_sequences(train_set_LA, n_step) # LA 훈련 데이터\n",
    "print(x_train_seq_LA.shape, y_train_seq_LA.shape)\n",
    "\n",
    "x_test_seq_LA, y_test_seq_LA = split_sequences(test_set_LA, n_step) # RA 훈련 레이블\n",
    "print(x_test_seq_LA.shape, y_test_seq_LA.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dba7cf89-1465-46d9-a624-2a6291f4bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#레이블 원핫인코딩\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_seq_RA = to_categorical(y_train_seq_RA) #RA 훈련 레이블 \n",
    "y_train_seq_LA = to_categorical(y_train_seq_LA) #LA 훈련 레이블\n",
    "\n",
    "y_test_seq_RA = to_categorical(y_test_seq_RA) #RA 테스트 레이블\n",
    "y_test_seq_LA = to_categorical(y_test_seq_LA) #RA 테스트 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1ea7223-5659-4829-9465-a80f7c45f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 54 19\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = x_train_seq_RA.shape[1], x_train_seq_RA.shape[2], y_train_seq_RA.shape[1]\n",
    "print(n_timesteps, n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45bce51d-bcf9-47ff-b846-9c549330195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DoHyeonjik\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m93,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)                  │           \u001b[38;5;34m2,451\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,659</span> (440.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,659\u001b[0m (440.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,659</span> (440.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m112,659\u001b[0m (440.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RA 모델 생성\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "# from keras.layers import \n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(n_timesteps, n_features)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1fba405-e285-40cf-8140-f0e74bdaa73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2025 - loss: 2.5692 - val_accuracy: 0.5263 - val_loss: 1.4297\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 1.1801 - val_accuracy: 0.7368 - val_loss: 0.9514\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.7567 - val_accuracy: 0.7792 - val_loss: 0.7875\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.6067 - val_accuracy: 0.8275 - val_loss: 0.7030\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.4842 - val_accuracy: 0.8275 - val_loss: 0.6939\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8780 - loss: 0.4059 - val_accuracy: 0.8538 - val_loss: 0.5954\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.3340 - val_accuracy: 0.8509 - val_loss: 0.6054\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2751 - val_accuracy: 0.8436 - val_loss: 0.5990\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.2417 - val_accuracy: 0.8275 - val_loss: 0.6243\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1997 - val_accuracy: 0.8480 - val_loss: 0.5837\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1485 - val_accuracy: 0.8275 - val_loss: 0.6602\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1363 - val_accuracy: 0.8480 - val_loss: 0.6081\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.1080 - val_accuracy: 0.8567 - val_loss: 0.5966\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.0775 - val_accuracy: 0.8596 - val_loss: 0.6449\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0704 - val_accuracy: 0.8509 - val_loss: 0.6377\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0531 - val_accuracy: 0.8509 - val_loss: 0.6550\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0425 - val_accuracy: 0.8596 - val_loss: 0.6839\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0271 - val_accuracy: 0.8699 - val_loss: 0.6794\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0267 - val_accuracy: 0.8684 - val_loss: 0.7337\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0251 - val_accuracy: 0.8626 - val_loss: 0.7695\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_seq_RA, y_train_seq_RA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e582a3bf-0c19-4c8f-99e5-75fe8b417fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6752218008041382, 0.8656716346740723]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "# model.evaluate(x_train_seq_RA, y_train_seq_RA)\n",
    "model.evaluate(x_test_seq_RA, y_test_seq_RA)\n",
    "#loss가 큼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61d21192-987e-4ed2-8b26-289e092c8508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "y_test_arg=np.argmax(y_test_seq_RA, axis=1)\n",
    "Y_pred = np.argmax(model.predict(x_test_seq_RA),axis=1)\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(y_test_arg, Y_pred)\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 6))  # 그래프 크기 조절 (너비 8, 높이 6)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "\n",
    "# 그래프 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42ea9e80-c52f-41ea-b4a9-6e6378914f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.6823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved at C:\\users\\DoHyeonjik\\Desktop\\RA_Model.h5\n",
      "86.56716346740723\n",
      "0.6752218008041382\n"
     ]
    }
   ],
   "source": [
    "base_loss, base_accuracy = model.evaluate(x_test_seq_RA, y_test_seq_RA) # model의 loss와 accuracy\n",
    "model_file = r'C:\\users\\DoHyeonjik\\Desktop\\RA_Model.h5' #위 경로에 저장\n",
    "\n",
    "keras.models.save_model(model, model_file, include_optimizer=False) # 모델 저장\n",
    "print('model saved at', model_file) \n",
    "score = base_accuracy*100 #퍼센트로 변환\n",
    "print(format(score))\n",
    "print(format(base_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed52d2a6-8a83-48dc-9141-ec0418019052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DoHyeonjik\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m93,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)                  │           \u001b[38;5;34m2,451\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,659</span> (440.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m112,659\u001b[0m (440.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,659</span> (440.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m112,659\u001b[0m (440.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LA 모델 생성\n",
    "model2 = keras.models.Sequential()\n",
    "model2.add(LSTM(units=128, input_shape=(n_timesteps, n_features)))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(n_outputs, activation='softmax'))\n",
    "model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2f4f61b-fb36-4e4d-93bb-ee51710b3c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2348 - loss: 2.4843 - val_accuracy: 0.6009 - val_loss: 1.2196\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 1.1050 - val_accuracy: 0.7266 - val_loss: 0.9176\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.7538 - val_accuracy: 0.8085 - val_loss: 0.6798\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.5433 - val_accuracy: 0.8114 - val_loss: 0.6634\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8734 - loss: 0.4422 - val_accuracy: 0.8509 - val_loss: 0.5790\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.3872 - val_accuracy: 0.8450 - val_loss: 0.5813\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.3124 - val_accuracy: 0.8465 - val_loss: 0.5922\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2529 - val_accuracy: 0.8801 - val_loss: 0.5133\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2092 - val_accuracy: 0.8596 - val_loss: 0.5506\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1839 - val_accuracy: 0.8655 - val_loss: 0.4917\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1321 - val_accuracy: 0.8787 - val_loss: 0.5140\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.1123 - val_accuracy: 0.8567 - val_loss: 0.5659\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.0974 - val_accuracy: 0.8889 - val_loss: 0.5396\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0904 - val_accuracy: 0.8860 - val_loss: 0.5372\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.0702 - val_accuracy: 0.8713 - val_loss: 0.5686\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0463 - val_accuracy: 0.8874 - val_loss: 0.5787\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0475 - val_accuracy: 0.8684 - val_loss: 0.6370\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0614 - val_accuracy: 0.8611 - val_loss: 0.6421\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0411 - val_accuracy: 0.8757 - val_loss: 0.6450\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0204 - val_accuracy: 0.8757 - val_loss: 0.6684\n"
     ]
    }
   ],
   "source": [
    "history2=model2.fit(x_train_seq_LA, y_train_seq_LA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f3aad98-46c4-4a80-a21e-967b583aa815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.6157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6560221910476685, 0.8687444925308228]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LA 모델 평가\n",
    "model2.evaluate(x_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85c7869f-ca39-4889-a176-a1776bc34bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.6157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved at C:\\users\\DoHyeonjik\\Desktop\\LA_Model.h5\n",
      "86.87444925308228\n",
      "0.6560221910476685\n"
     ]
    }
   ],
   "source": [
    "base_loss2, base_accuracy2 = model2.evaluate(x_test_seq_LA, y_test_seq_LA) # model의 loss와 accuracy\n",
    "model_file2 = r'C:\\users\\DoHyeonjik\\Desktop\\LA_Model.h5' #위 경로에 저장\n",
    "\n",
    "keras.models.save_model(model2, model_file2, include_optimizer=False) # 모델 저장\n",
    "print('model saved at', model_file2) \n",
    "score2 = base_accuracy2*100 #퍼센트로 변환\n",
    "print(format(score2))\n",
    "print(format(base_loss2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115174de-1982-4285-9c52-09699fe3913c",
   "metadata": {},
   "source": [
    "# 전이 학습 시작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "020f02d1-a884-4dd5-9b91-20f7800c3efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 1) 모델 불러오기\n",
    "base_model = keras.models.load_model(model_file2) #base_model은 LA 모델이 들어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edab1253-12cd-49bc-9d21-e1bb93e857bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8808 - loss: 0.6157 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6560221910476685, 0.8687444925308228]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 기존 모델 평가\n",
    "base_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "base_model.evaluate(x_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59656f39-a55a-45e6-8f61-c29a798fdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2527 - loss: 5.2841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.12110710144043, 0.263827919960022]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) LA 모델에 RA 데이터 evaluate\n",
    "base_model.evaluate(x_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80c41af3-56b8-4b0f-a8a9-d1fccad2e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<LSTM name=lstm_1, built=True>, <Dense name=dense_2, built=True>]\n"
     ]
    }
   ],
   "source": [
    "# 4) 전이학습 시작\n",
    "base_model.trainable = False #기존의 모델 동결\n",
    "\n",
    "#함수: 모델의 레이어를 뒷부분을 잘라내는 함수\n",
    "def remove_last_layers(model, num_layers_to_remove):\n",
    "    model_layers = model.layers[:-num_layers_to_remove]\n",
    "    print(model_layers)\n",
    "    new_model= keras.models.Sequential(model_layers)\n",
    "    return new_model\n",
    "\n",
    "#모델의 기존의 출력층 제거\n",
    "new_model = remove_last_layers(base_model, 1)\n",
    "\n",
    "#새로운 출력층 추가\n",
    "new_model.add(Dense(256, activation='relu'))\n",
    "new_model.add(Dense(n_outputs, activation='softmax'))\n",
    "new_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12f824b2-90b6-4974-82b9-8688322cef25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;LSTM name=lstm_1, built=True&gt;</td>\n",
       "      <td>lstm_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Dense name=dense_2, built=True&gt;</td>\n",
       "      <td>dense_2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Dense name=dense_6, built=False&gt;</td>\n",
       "      <td>dense_6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Dense name=dense_7, built=False&gt;</td>\n",
       "      <td>dense_7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Layer Type Layer Name  Layer Trainable\n",
       "0     <LSTM name=lstm_1, built=True>     lstm_1            False\n",
       "1   <Dense name=dense_2, built=True>    dense_2            False\n",
       "2  <Dense name=dense_6, built=False>    dense_6             True\n",
       "3  <Dense name=dense_7, built=False>    dense_7             True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6)모델 확인\n",
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f71b1ff1-27af-4adf-9cc2-3073bffcefbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2530 - loss: 2.5513 - val_accuracy: 0.4649 - val_loss: 1.7491\n",
      "Epoch 2/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5226 - loss: 1.5453 - val_accuracy: 0.5132 - val_loss: 1.5509\n",
      "Epoch 3/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5434 - loss: 1.4105 - val_accuracy: 0.4474 - val_loss: 1.5859\n",
      "Epoch 4/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5610 - loss: 1.3442 - val_accuracy: 0.5000 - val_loss: 1.5459\n",
      "Epoch 5/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 1.2190 - val_accuracy: 0.5482 - val_loss: 1.4491\n",
      "Epoch 6/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 1.2324 - val_accuracy: 0.5088 - val_loss: 1.4554\n",
      "Epoch 7/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6067 - loss: 1.1949 - val_accuracy: 0.5395 - val_loss: 1.4581\n",
      "Epoch 8/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 1.1580 - val_accuracy: 0.5395 - val_loss: 1.4069\n",
      "Epoch 9/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6694 - loss: 1.0411 - val_accuracy: 0.5833 - val_loss: 1.3888\n",
      "Epoch 10/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6842 - loss: 0.9838 - val_accuracy: 0.5439 - val_loss: 1.3513\n",
      "Epoch 11/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.9894 - val_accuracy: 0.5570 - val_loss: 1.3840\n",
      "Epoch 12/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6594 - loss: 1.0401 - val_accuracy: 0.5965 - val_loss: 1.3191\n",
      "Epoch 13/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.9414 - val_accuracy: 0.5482 - val_loss: 1.3407\n",
      "Epoch 14/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.9573 - val_accuracy: 0.5395 - val_loss: 1.3756\n",
      "Epoch 15/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.8738 - val_accuracy: 0.5746 - val_loss: 1.3322\n",
      "Epoch 16/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.8229 - val_accuracy: 0.5658 - val_loss: 1.3231\n",
      "Epoch 17/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7570 - loss: 0.8213 - val_accuracy: 0.5395 - val_loss: 1.3787\n",
      "Epoch 18/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.7842 - val_accuracy: 0.5175 - val_loss: 1.3642\n",
      "Epoch 19/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.7564 - val_accuracy: 0.5570 - val_loss: 1.3191\n",
      "Epoch 20/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7746 - loss: 0.7384 - val_accuracy: 0.5526 - val_loss: 1.3433\n"
     ]
    }
   ],
   "source": [
    "# 7)모델 훈련\n",
    "history3 = new_model.fit(x_test_seq_RA, y_test_seq_RA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0028d7b4-b382-48ed-ad61-d9018b362cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7752 - loss: 0.7034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7656369209289551, 0.753731369972229]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8)훈련한 모델 평가\n",
    "new_model.evaluate(x_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efead848-3199-499c-bf94-23c1f2854cb8",
   "metadata": {},
   "source": [
    "#### 이미 성능이 많이 올라옴\n",
    "\n",
    "#### 미세 조정을 통해서 모델 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86773179-5b8a-41a3-8dbb-ae2f94c66761",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=True\n",
    "new_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9aaaf17d-bbaf-4aba-970c-2bb8350a6b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;LSTM name=lstm_1, built=True&gt;</td>\n",
       "      <td>lstm_1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Dense name=dense_2, built=True&gt;</td>\n",
       "      <td>dense_2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Dense name=dense_6, built=True&gt;</td>\n",
       "      <td>dense_6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Dense name=dense_7, built=True&gt;</td>\n",
       "      <td>dense_7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Layer Type Layer Name  Layer Trainable\n",
       "0    <LSTM name=lstm_1, built=True>     lstm_1             True\n",
       "1  <Dense name=dense_2, built=True>    dense_2             True\n",
       "2  <Dense name=dense_6, built=True>    dense_6             True\n",
       "3  <Dense name=dense_7, built=True>    dense_7             True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "140abeaf-4214-4c40-a893-b9d110720e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 1.1281 - val_accuracy: 0.7749 - val_loss: 0.8290\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.6191 - val_accuracy: 0.7939 - val_loss: 0.7548\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.4520 - val_accuracy: 0.8275 - val_loss: 0.6784\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9000 - loss: 0.3563 - val_accuracy: 0.8319 - val_loss: 0.6172\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.2637 - val_accuracy: 0.8304 - val_loss: 0.6292\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.2147 - val_accuracy: 0.8231 - val_loss: 0.6541\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9498 - loss: 0.1688 - val_accuracy: 0.8582 - val_loss: 0.6014\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1460 - val_accuracy: 0.8363 - val_loss: 0.6406\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.1000 - val_accuracy: 0.8377 - val_loss: 0.6361\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.0932 - val_accuracy: 0.8333 - val_loss: 0.6894\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0734 - val_accuracy: 0.8553 - val_loss: 0.6894\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0811 - val_accuracy: 0.8553 - val_loss: 0.7139\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0509 - val_accuracy: 0.8436 - val_loss: 0.7225\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0430 - val_accuracy: 0.8450 - val_loss: 0.7791\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0326 - val_accuracy: 0.8582 - val_loss: 0.7971\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0493 - val_accuracy: 0.8523 - val_loss: 0.8055\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0365 - val_accuracy: 0.8509 - val_loss: 0.7826\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0329 - val_accuracy: 0.8553 - val_loss: 0.8283\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0415 - val_accuracy: 0.8523 - val_loss: 0.8239\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0745 - val_accuracy: 0.8392 - val_loss: 0.8358\n"
     ]
    }
   ],
   "source": [
    "history4= new_model.fit(x_train_seq_RA, y_train_seq_RA, epochs = 20 , batch_size=32, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "622acc0a-21f5-4883-9474-1cf57a845765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8559 - loss: 0.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8523181676864624, 0.8489903211593628]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(x_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac732f01-90a8-4c56-9e0a-1392973ebe98",
   "metadata": {},
   "source": [
    "#### 모델의 정확도가 더 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235641d1-fafb-4029-81e4-a52088833f96",
   "metadata": {},
   "source": [
    "_______\n",
    "## RA 모델에 LA 데이터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fdb6fb90-a67e-4440-931e-ae8426dc1ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 1) 모델 불러오기\n",
    "base_model_RA = keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72ff8313-581b-452c-b270-f363db765d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.6823 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6752218008041382, 0.8656716346740723]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 모델 확인\n",
    "base_model_RA.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "base_model_RA.evaluate(x_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3524dabb-b8fb-42b3-9cdf-ba9ba1a931ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2398 - loss: 6.5632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.5398969650268555, 0.2287093997001648]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) RA 모델에 LA 데이터 넣어보기\n",
    "base_model_RA.evaluate(x_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f014b14-0808-4b50-a814-28162133b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<LSTM name=lstm, built=True>, <Dense name=dense, built=True>]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m93,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,208</span> (430.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,208\u001b[0m (430.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,208</span> (430.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m110,208\u001b[0m (430.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4) 전이 학습 시작\n",
    "# 4-1) 기존 모델 동결\n",
    "base_model_RA.trainable = False\n",
    "\n",
    "# 4-2) 출력층 레이어 삭제\n",
    "new_model_RA = remove_last_layers(base_model_RA, 1)\n",
    "\n",
    "# 4-3) 모델에 새 출력층 생성\n",
    "new_model_RA.add(Dense(256, activation='relu'))\n",
    "new_model_RA.add(Dense(n_outputs, activation='softmax'))\n",
    "new_model_RA.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "# 4-4) 모델 요약\n",
    "new_model_RA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee6dfd64-555d-40d5-aa20-509feba9bf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3387 - loss: 2.1558 - val_accuracy: 0.5058 - val_loss: 1.4860\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5517 - loss: 1.3834 - val_accuracy: 0.5526 - val_loss: 1.3485\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5778 - loss: 1.2497 - val_accuracy: 0.5599 - val_loss: 1.3204\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 1.1884 - val_accuracy: 0.5833 - val_loss: 1.2845\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6180 - loss: 1.1476 - val_accuracy: 0.6067 - val_loss: 1.2444\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6370 - loss: 1.1009 - val_accuracy: 0.6009 - val_loss: 1.2329\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6540 - loss: 1.0430 - val_accuracy: 0.6067 - val_loss: 1.2044\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6786 - loss: 0.9938 - val_accuracy: 0.6067 - val_loss: 1.2178\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.9761 - val_accuracy: 0.6199 - val_loss: 1.2308\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6923 - loss: 0.9286 - val_accuracy: 0.6404 - val_loss: 1.1711\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7041 - loss: 0.8883 - val_accuracy: 0.6462 - val_loss: 1.1429\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7116 - loss: 0.8829 - val_accuracy: 0.6594 - val_loss: 1.1384\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7289 - loss: 0.8347 - val_accuracy: 0.6477 - val_loss: 1.1619\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.8310 - val_accuracy: 0.6404 - val_loss: 1.1296\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7444 - loss: 0.7846 - val_accuracy: 0.6740 - val_loss: 1.1317\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7483 - loss: 0.7743 - val_accuracy: 0.6608 - val_loss: 1.1237\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.7314 - val_accuracy: 0.6330 - val_loss: 1.1581\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7530 - loss: 0.7456 - val_accuracy: 0.6725 - val_loss: 1.1397\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7567 - loss: 0.7196 - val_accuracy: 0.6623 - val_loss: 1.1227\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7682 - loss: 0.7035 - val_accuracy: 0.6608 - val_loss: 1.1429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ef77676310>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) RA 모델에 LA 데이터 학습\n",
    "new_model_RA.fit(x_train_seq_LA, y_train_seq_LA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78acb78f-b72a-4bbc-bca9-75a60dae1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6557 - loss: 1.1327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1605277061462402, 0.6518875956535339]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 새 모델 평가\n",
    "new_model_RA.evaluate(x_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1289f214-1de5-4420-b2b7-9de7cc4637c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;LSTM name=lstm, built=True&gt;</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Dense name=dense, built=True&gt;</td>\n",
       "      <td>dense</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Dense name=dense_14, built=True&gt;</td>\n",
       "      <td>dense_14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Dense name=dense_15, built=True&gt;</td>\n",
       "      <td>dense_15</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Layer Type Layer Name  Layer Trainable\n",
       "0       <LSTM name=lstm, built=True>       lstm             True\n",
       "1     <Dense name=dense, built=True>      dense             True\n",
       "2  <Dense name=dense_14, built=True>   dense_14             True\n",
       "3  <Dense name=dense_15, built=True>   dense_15             True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) 미세조정\n",
    "# 기존의 모델 동결 해제\n",
    "base_model_RA.trainable=True\n",
    "new_model_RA.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "# 동결 해제 여부 확인\n",
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in new_model_RA.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c9bad63-1068-47d0-9665-1184d961c379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7567 - loss: 0.7232 - val_accuracy: 0.7368 - val_loss: 0.8529\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8532 - loss: 0.4603 - val_accuracy: 0.7705 - val_loss: 0.7863\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3525 - val_accuracy: 0.7953 - val_loss: 0.7255\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2613 - val_accuracy: 0.7909 - val_loss: 0.7467\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2099 - val_accuracy: 0.8099 - val_loss: 0.6868\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1642 - val_accuracy: 0.8392 - val_loss: 0.6354\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1080 - val_accuracy: 0.8216 - val_loss: 0.6730\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0965 - val_accuracy: 0.8275 - val_loss: 0.8199\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0907 - val_accuracy: 0.8085 - val_loss: 0.7949\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9694 - loss: 0.1008 - val_accuracy: 0.8289 - val_loss: 0.7651\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.0745 - val_accuracy: 0.8319 - val_loss: 0.8145\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0562 - val_accuracy: 0.8421 - val_loss: 0.8312\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9735 - loss: 0.0757 - val_accuracy: 0.8304 - val_loss: 0.8989\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.0573 - val_accuracy: 0.8143 - val_loss: 0.8796\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0380 - val_accuracy: 0.8333 - val_loss: 0.9258\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0587 - val_accuracy: 0.8421 - val_loss: 0.8958\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0647 - val_accuracy: 0.8056 - val_loss: 1.0172\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0590 - val_accuracy: 0.8494 - val_loss: 0.9226\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0263 - val_accuracy: 0.8421 - val_loss: 0.9000\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0517 - val_accuracy: 0.8392 - val_loss: 0.9447\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9378698468208313, 0.8441615700721741]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) 미세조정한 모델 훈련\n",
    "history4 = new_model_RA.fit(x_train_seq_LA, y_train_seq_LA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)\n",
    "\n",
    "new_model_RA.evaluate(x_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6ffd9-143e-412c-9a0f-7163a14d7a1a",
   "metadata": {},
   "source": [
    "#### 모델의 성능이 높아진 것을 볼 수있다\n",
    "우하하"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715524e-5abc-48fb-a406-68cc0cae6894",
   "metadata": {},
   "source": [
    "________________________________\n",
    "## (추가)LSTM을 제외한 두개의 Dense층 모두 제거 후 전이학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1d859a17-9d72-4aef-8e54-ccbf1ae60c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.6823 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6752218008041382, 0.8656716346740723]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) RA 모델 불러오기\n",
    "RA_model = keras.models.load_model(model_file)\n",
    "\n",
    "# 2) 컴파일 후 확인\n",
    "RA_model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "RA_model.evaluate(x_test_seq_RA, y_test_seq_RA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d639475-1073-4208-a4f4-f2906faadfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<LSTM name=lstm, built=True>]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m93,696\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> (366.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,696\u001b[0m (366.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> (366.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m93,696\u001b[0m (366.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) 전이학습시작\n",
    "# 3_1) 기존 모델 동결\n",
    "RA_model.trainable = False\n",
    "\n",
    "# 3_2) 출력층 레이어 두개 삭제\n",
    "model_RA = remove_last_layers(RA_model, 2)\n",
    "model_RA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "713f576c-258b-4743-b60e-03330dd7a691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m93,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> (366.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,696\u001b[0m (366.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,696</span> (366.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m93,696\u001b[0m (366.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3_3) 모델에 새 출력층 생성\n",
    "model_RA.add(Dense(128, activation='relu'))\n",
    "model_RA.add(Dense(n_outputs, activation='softmax'))\n",
    "model_RA.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "# 3_4) 모델 요약\n",
    "model_RA.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b6636fcc-b602-4374-a2cd-d3eaaa1865f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2657 - loss: 2.4458 - val_accuracy: 0.5424 - val_loss: 1.4759\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5820 - loss: 1.3594 - val_accuracy: 0.5556 - val_loss: 1.2889\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6196 - loss: 1.1758 - val_accuracy: 0.6053 - val_loss: 1.1749\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6538 - loss: 1.0628 - val_accuracy: 0.6360 - val_loss: 1.1066\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6870 - loss: 0.9958 - val_accuracy: 0.6652 - val_loss: 1.0542\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7164 - loss: 0.9314 - val_accuracy: 0.6696 - val_loss: 1.0648\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7231 - loss: 0.8951 - val_accuracy: 0.6901 - val_loss: 1.0184\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.8504 - val_accuracy: 0.6857 - val_loss: 1.0179\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.8181 - val_accuracy: 0.6944 - val_loss: 0.9933\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7485 - loss: 0.7906 - val_accuracy: 0.6813 - val_loss: 1.0062\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7534 - loss: 0.7716 - val_accuracy: 0.6988 - val_loss: 0.9662\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7650 - loss: 0.7431 - val_accuracy: 0.7061 - val_loss: 0.9630\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7787 - loss: 0.7175 - val_accuracy: 0.7047 - val_loss: 0.9571\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7886 - loss: 0.6722 - val_accuracy: 0.6988 - val_loss: 0.9573\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.6534 - val_accuracy: 0.7149 - val_loss: 0.9409\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8045 - loss: 0.6421 - val_accuracy: 0.7164 - val_loss: 0.9432\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8007 - loss: 0.6300 - val_accuracy: 0.7076 - val_loss: 0.9371\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.6168 - val_accuracy: 0.7047 - val_loss: 0.9533\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8213 - loss: 0.5870 - val_accuracy: 0.7047 - val_loss: 0.9250\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.5896 - val_accuracy: 0.7091 - val_loss: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2ef7db41a90>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) 모델 훈련\n",
    "model_RA.fit(x_train_seq_LA, y_train_seq_LA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a98215f6-2b99-4511-b69d-aec156bf2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6962 - loss: 0.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9864743947982788, 0.6944688558578491]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RA.evaluate(x_test_seq_LA, y_test_seq_LA)\n",
    "# 미세하게 좋아짐 (loss: 1.16 -> 0.98 / acc : 0.65->0.69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f7da1a6a-3a1f-4f2c-843d-e3f4a1ece4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;LSTM name=lstm, built=True&gt;</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Dense name=dense_20, built=True&gt;</td>\n",
       "      <td>dense_20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Dense name=dense_21, built=True&gt;</td>\n",
       "      <td>dense_21</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Layer Type Layer Name  Layer Trainable\n",
       "0       <LSTM name=lstm, built=True>       lstm             True\n",
       "1  <Dense name=dense_20, built=True>   dense_20             True\n",
       "2  <Dense name=dense_21, built=True>   dense_21             True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5)미세조정\n",
    "RA_model.trainable= True\n",
    "model_RA.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "# 동결해제 여부 확인\n",
    "import pandas as pd\n",
    "display_layers = [(layer, layer.name, layer.trainable) for layer in model_RA.layers]\n",
    "pd.DataFrame(display_layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5b9455af-919d-493d-a9aa-50d5d295b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.5943 - val_accuracy: 0.7895 - val_loss: 0.7056\n",
      "Epoch 2/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.3701 - val_accuracy: 0.7836 - val_loss: 0.6903\n",
      "Epoch 3/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2881 - val_accuracy: 0.8114 - val_loss: 0.6633\n",
      "Epoch 4/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.2133 - val_accuracy: 0.8070 - val_loss: 0.6186\n",
      "Epoch 5/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9520 - loss: 0.1575 - val_accuracy: 0.8377 - val_loss: 0.5981\n",
      "Epoch 6/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1232 - val_accuracy: 0.8406 - val_loss: 0.6299\n",
      "Epoch 7/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0974 - val_accuracy: 0.8450 - val_loss: 0.6017\n",
      "Epoch 8/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1007 - val_accuracy: 0.8333 - val_loss: 0.6271\n",
      "Epoch 9/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0655 - val_accuracy: 0.8392 - val_loss: 0.6507\n",
      "Epoch 10/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0463 - val_accuracy: 0.8333 - val_loss: 0.6675\n",
      "Epoch 11/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0510 - val_accuracy: 0.8553 - val_loss: 0.6367\n",
      "Epoch 12/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0443 - val_accuracy: 0.8348 - val_loss: 0.6923\n",
      "Epoch 13/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0296 - val_accuracy: 0.8494 - val_loss: 0.6854\n",
      "Epoch 14/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0253 - val_accuracy: 0.8538 - val_loss: 0.6852\n",
      "Epoch 15/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0164 - val_accuracy: 0.8494 - val_loss: 0.6845\n",
      "Epoch 16/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0152 - val_accuracy: 0.8640 - val_loss: 0.6768\n",
      "Epoch 17/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8640 - val_loss: 0.7070\n",
      "Epoch 18/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8684 - val_loss: 0.6845\n",
      "Epoch 19/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8684 - val_loss: 0.6887\n",
      "Epoch 20/20\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8670 - val_loss: 0.7075\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8708 - loss: 0.6860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7073639631271362, 0.8634767532348633]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 미세조정한 모델 훈련\n",
    "history4 = model_RA.fit(x_train_seq_LA, y_train_seq_LA, epochs=20, batch_size=32, validation_split=0.1, shuffle=True)\n",
    "model_RA.evaluate(x_test_seq_LA, y_test_seq_LA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e9bba-bcc9-48a1-b0f2-ee928381d277",
   "metadata": {},
   "source": [
    "#### 결과 : acc의 변화는 크지 않지만 loss 값이 많이 개선되었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5a854-193d-4230-8215-a59c1201a65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
