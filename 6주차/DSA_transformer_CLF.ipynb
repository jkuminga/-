{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6199855c-6a8c-4505-97d6-d1a36a90a20d",
   "metadata": {},
   "source": [
    "# 트랜스포머로 DSA 데이터 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "768b00f7-0d3c-4957-a2a7-58c4def8a9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9120, 272)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(r\"C:\\Users\\DoHyeonjik\\GachonUniv\\3-2\\datasets\\DL\\DSA_features.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "86872524-a3b2-43c0-8ad2-efa07095b5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "sitting                    480\n",
       "walkingTreadmillIncline    480\n",
       "jumping                    480\n",
       "rowing                     480\n",
       "cyclingVertical            480\n",
       "cyclingHorizontal          480\n",
       "crossTrainer               480\n",
       "stepper                    480\n",
       "runningTreadmill           480\n",
       "walkingTreadmillFlat       480\n",
       "standing                   480\n",
       "walkingLot                 480\n",
       "movingInElevator           480\n",
       "standingInElevatorStill    480\n",
       "decendingStairs            480\n",
       "ascendingStairs            480\n",
       "lyingRigh                  480\n",
       "lyingBack                  480\n",
       "basketBall                 480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0e09387-0fd7-4275-ac11-0d9d981b6e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9120, 54) (9120, 54)\n"
     ]
    }
   ],
   "source": [
    "#df_RA랑 LA로 나누기\n",
    "df_RA = df.filter(regex='RA_')\n",
    "df_LA = df.filter(regex='LA_')\n",
    "print(df_RA.shape, df_LA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a02c5adf-8b9e-40e9-a906-995bde121f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터에 레이블 삽입\n",
    "df_RA.insert(54, 'activity', df['activity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ed6e523-9833-40b5-adc2-225089449f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\TempFolder\\ipykernel_17992\\2372902343.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RA['activity'] = le.fit_transform(df_RA['activity'])\n"
     ]
    }
   ],
   "source": [
    "# 레이블 값을 라벨인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le= LabelEncoder()\n",
    "df_RA['activity'] = le.fit_transform(df_RA['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "356b0b08-8d4a-4915-8a52-5dad0469ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 분리 \n",
    "df_RA_label = df_RA['activity']\n",
    "df_RA_data = df_RA.drop('activity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dbc69d6-6450-4bbc-b934-526dbc12dc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6840, 54)\n",
      "(2280, 54)\n",
      "(6840,)\n"
     ]
    }
   ],
   "source": [
    "#traindata와 testdata로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_RA, x_test_RA, y_train_RA, y_test_RA = train_test_split(df_RA_data, df_RA_label, test_size=0.25, random_state=21)\n",
    "print(x_train_RA.shape)\n",
    "print(x_test_RA.shape)\n",
    "print(y_train_RA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6745ce1-fc47-47f7-81a9-78243a160034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()  # 빈 리스트를 생성하여 시퀀스 데이터와 레이블을 담을 공간을 만듦\n",
    "    for i in range(len(sequences)):  # 전체 시퀀스 데이터를 순회\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps  # 현재 인덱스(i)에서 n_steps만큼 떨어진 시퀀스의 끝을 계산\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):  # 시퀀스 끝이 데이터의 범위를 넘어서는지 확인\n",
    "            break  # 범위를 넘으면 루프 종료\n",
    "        # gather input (X) and output parts (y)\n",
    "        seq_x = sequences[i:end_ix, :-1]  # 입력 데이터 (특징 데이터)\n",
    "        seq_y_values = sequences[i:end_ix, -1]  # 시퀀스 동안의 출력 데이터 (레이블들)\n",
    "            \n",
    "        # 가장 빈번하게 나온 레이블 찾기\n",
    "        most_common_label = Counter(seq_y_values).most_common(1)[0][0]\n",
    "        if i ==0: print(most_common_label)\n",
    "        \n",
    "        X.append(seq_x)  # 입력 데이터 추가\n",
    "        y.append(most_common_label)  # 가장 많이 나온 레이블 추가\n",
    "    \n",
    "    return np.array(X), np.array(y)  # 리스트를 numpy 배열로 변환하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64186eca-e2b6-4257-b274-8bd4797e5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6840, 55)\n"
     ]
    }
   ],
   "source": [
    "#Merge train and test x/y data to apply sequence transformation function\n",
    "#훈련 데이터와 테스트 데이터의 레이블과 데이터를 병합 -> 시퀀스 변형을 위해서\n",
    "y_train_array_RA = np.array(y_train_RA) #RA의 훈련 레이블을 넘파이로 바꾸고\n",
    "train_set_RA = np.c_[x_train_RA, y_train_array_RA] #RA의 훈련데이터와 훈련레이블을 병합\n",
    "print(train_set_RA.shape)\n",
    "\n",
    "y_test_array_RA = np.array(y_test_RA) #RA의 테스트 레이블을 넘파이로 바꾸고\n",
    "test_set_RA = np.c_[x_test_RA, y_test_array_RA] #RA의 테스트데이터와 테스트레이블을 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33db3418-da24-49ed-bc17-07299efe4d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "(6838, 3, 54) (6838,)\n",
      "7.0\n",
      "(2278, 3, 54) (2278,)\n",
      "9.0\n",
      "(6838, 3, 54) (6838,)\n",
      "7.0\n",
      "(2278, 3, 54) (2278,)\n"
     ]
    }
   ],
   "source": [
    "#split_sequence 적용\n",
    "n_step = 3 \n",
    "\n",
    "x_train_seq_RA, y_train_seq_RA = split_sequences(train_set_RA, n_step) # RA 훈련 데이터\n",
    "print(x_train_seq_RA.shape, y_train_seq_RA.shape)\n",
    "\n",
    "x_test_seq_RA, y_test_seq_RA = split_sequences(test_set_RA, n_step) # RA 훈련 레이블\n",
    "print(x_test_seq_RA.shape, y_test_seq_RA.shape)\n",
    "\n",
    "x_train_seq_LA, y_train_seq_LA = split_sequences(train_set_LA, n_step) # LA 훈련 데이터\n",
    "print(x_train_seq_LA.shape, y_train_seq_LA.shape)\n",
    "\n",
    "x_test_seq_LA, y_test_seq_LA = split_sequences(test_set_LA, n_step) # RA 훈련 레이블\n",
    "print(x_test_seq_LA.shape, y_test_seq_LA.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f76b10ba-f747-4bcc-b001-dae3b9166bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838,)\n"
     ]
    }
   ],
   "source": [
    "#레이블 원핫인코딩\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# y_train_seq_RA = to_categorical(y_train_seq_RA) #RA 훈련 레이블 \n",
    "# \n",
    "# y_test_seq_RA = to_categorical(y_test_seq_RA) #RA 테스트 레이블\n",
    "\n",
    "print(y_train_seq_RA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89e11d46-cad3-4520-89f0-452ab3497379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import MultiHeadAttention\n",
    "from keras import layers\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x=layers.MultiHeadAttention(key_dim = head_size, num_heads = num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x=layers.Dropout(dropout)(x)\n",
    "    x=layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = layers.Conv1D(filters = ff_dim, kernel_size=1, activation='relu')(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res\n",
    "                     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7626db71-58c9-4a70-803f-8bf7ac933233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 함수\n",
    "def build_model(input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, mlp_units, dropout=0, mlp_dropout=0):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    x= inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation='relu')(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd9a0742-8ae5-4115-b1e9-5a80f40e1edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">224,310</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,451</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │         \u001b[38;5;34m224,310\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │             \u001b[38;5;34m108\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m220\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │             \u001b[38;5;34m270\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │             \u001b[38;5;34m108\u001b[0m │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m54\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m7,040\u001b[0m │ global_average_pooling1d_… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)                │           \u001b[38;5;34m2,451\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,507</span> (916.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,507\u001b[0m (916.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,507</span> (916.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,507\u001b[0m (916.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = x_train_seq_RA.shape[1:]\n",
    "n_classes = 19\n",
    "\n",
    "model = build_model(input_shape, head_size= 256, num_heads=4, ff_dim=4, num_transformer_blocks=1, mlp_units=[128], mlp_dropout=0.4, dropout=0.25)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "112264b4-3019-46cf-bcac-727dbdb52364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 4.5951 - sparse_categorical_accuracy: 0.0854 - val_loss: 2.6944 - val_sparse_categorical_accuracy: 0.2054\n",
      "Epoch 2/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 2.8910 - sparse_categorical_accuracy: 0.1514 - val_loss: 2.5950 - val_sparse_categorical_accuracy: 0.2434\n",
      "Epoch 3/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.7030 - sparse_categorical_accuracy: 0.1857 - val_loss: 2.4713 - val_sparse_categorical_accuracy: 0.2683\n",
      "Epoch 4/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2.5522 - sparse_categorical_accuracy: 0.2278 - val_loss: 2.4042 - val_sparse_categorical_accuracy: 0.2727\n",
      "Epoch 5/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.5266 - sparse_categorical_accuracy: 0.2279 - val_loss: 2.3331 - val_sparse_categorical_accuracy: 0.2887\n",
      "Epoch 6/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.4129 - sparse_categorical_accuracy: 0.2532 - val_loss: 2.2465 - val_sparse_categorical_accuracy: 0.3070\n",
      "Epoch 7/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2.3810 - sparse_categorical_accuracy: 0.2555 - val_loss: 2.2021 - val_sparse_categorical_accuracy: 0.3107\n",
      "Epoch 8/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.3000 - sparse_categorical_accuracy: 0.2762 - val_loss: 2.1514 - val_sparse_categorical_accuracy: 0.3341\n",
      "Epoch 9/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.2337 - sparse_categorical_accuracy: 0.2899 - val_loss: 2.1430 - val_sparse_categorical_accuracy: 0.3194\n",
      "Epoch 10/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2.2240 - sparse_categorical_accuracy: 0.2868 - val_loss: 2.0994 - val_sparse_categorical_accuracy: 0.3275\n",
      "Epoch 11/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2.2085 - sparse_categorical_accuracy: 0.2993 - val_loss: 2.0773 - val_sparse_categorical_accuracy: 0.3333\n",
      "Epoch 12/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.1532 - sparse_categorical_accuracy: 0.3151 - val_loss: 2.0448 - val_sparse_categorical_accuracy: 0.3370\n",
      "Epoch 13/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2.1448 - sparse_categorical_accuracy: 0.3130 - val_loss: 2.0232 - val_sparse_categorical_accuracy: 0.3494\n",
      "Epoch 14/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.1141 - sparse_categorical_accuracy: 0.3194 - val_loss: 2.0342 - val_sparse_categorical_accuracy: 0.3348\n",
      "Epoch 15/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 2.0986 - sparse_categorical_accuracy: 0.3248 - val_loss: 2.0148 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 16/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 2.0700 - sparse_categorical_accuracy: 0.3262 - val_loss: 1.9835 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 17/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2.0287 - sparse_categorical_accuracy: 0.3358 - val_loss: 2.0058 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 18/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 2.0730 - sparse_categorical_accuracy: 0.3200 - val_loss: 2.0082 - val_sparse_categorical_accuracy: 0.3363\n",
      "Epoch 19/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.9896 - sparse_categorical_accuracy: 0.3573 - val_loss: 1.9472 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 20/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.9737 - sparse_categorical_accuracy: 0.3575 - val_loss: 1.9592 - val_sparse_categorical_accuracy: 0.3458\n",
      "Epoch 21/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.9619 - sparse_categorical_accuracy: 0.3413 - val_loss: 1.9582 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 22/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.9616 - sparse_categorical_accuracy: 0.3489 - val_loss: 1.9284 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 23/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.9824 - sparse_categorical_accuracy: 0.3391 - val_loss: 1.9000 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 24/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.9267 - sparse_categorical_accuracy: 0.3573 - val_loss: 1.8980 - val_sparse_categorical_accuracy: 0.3450\n",
      "Epoch 25/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.9284 - sparse_categorical_accuracy: 0.3472 - val_loss: 1.9132 - val_sparse_categorical_accuracy: 0.3655\n",
      "Epoch 26/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.8935 - sparse_categorical_accuracy: 0.3751 - val_loss: 1.9183 - val_sparse_categorical_accuracy: 0.3684\n",
      "Epoch 27/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.9117 - sparse_categorical_accuracy: 0.3612 - val_loss: 1.9018 - val_sparse_categorical_accuracy: 0.3494\n",
      "Epoch 28/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.8495 - sparse_categorical_accuracy: 0.3756 - val_loss: 1.8814 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 29/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.8819 - sparse_categorical_accuracy: 0.3656 - val_loss: 1.9028 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 30/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.8837 - sparse_categorical_accuracy: 0.3600 - val_loss: 1.8888 - val_sparse_categorical_accuracy: 0.3692\n",
      "Epoch 31/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 1.8557 - sparse_categorical_accuracy: 0.3713 - val_loss: 1.8586 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 32/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.8834 - sparse_categorical_accuracy: 0.3568 - val_loss: 1.9147 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 33/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.8477 - sparse_categorical_accuracy: 0.3805 - val_loss: 1.9060 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 34/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 1.8492 - sparse_categorical_accuracy: 0.3729 - val_loss: 1.8949 - val_sparse_categorical_accuracy: 0.3494\n",
      "Epoch 35/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.8393 - sparse_categorical_accuracy: 0.3762 - val_loss: 1.8439 - val_sparse_categorical_accuracy: 0.3662\n",
      "Epoch 36/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.7994 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.8470 - val_sparse_categorical_accuracy: 0.3648\n",
      "Epoch 37/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.8233 - sparse_categorical_accuracy: 0.3722 - val_loss: 1.8647 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 38/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.7879 - sparse_categorical_accuracy: 0.3864 - val_loss: 1.8634 - val_sparse_categorical_accuracy: 0.3648\n",
      "Epoch 39/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.8199 - sparse_categorical_accuracy: 0.3771 - val_loss: 1.8852 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 40/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.7877 - sparse_categorical_accuracy: 0.3887 - val_loss: 1.8297 - val_sparse_categorical_accuracy: 0.3838\n",
      "Epoch 41/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.7800 - sparse_categorical_accuracy: 0.3881 - val_loss: 1.8315 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 42/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.8113 - sparse_categorical_accuracy: 0.3768 - val_loss: 1.8731 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 43/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.7560 - sparse_categorical_accuracy: 0.3993 - val_loss: 1.8172 - val_sparse_categorical_accuracy: 0.3699\n",
      "Epoch 44/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.7655 - sparse_categorical_accuracy: 0.3958 - val_loss: 1.8399 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 45/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.7669 - sparse_categorical_accuracy: 0.3772 - val_loss: 1.8378 - val_sparse_categorical_accuracy: 0.3699\n",
      "Epoch 46/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.7654 - sparse_categorical_accuracy: 0.3837 - val_loss: 1.8031 - val_sparse_categorical_accuracy: 0.3582\n",
      "Epoch 47/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.7332 - sparse_categorical_accuracy: 0.4100 - val_loss: 1.8627 - val_sparse_categorical_accuracy: 0.3589\n",
      "Epoch 48/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.7643 - sparse_categorical_accuracy: 0.4009 - val_loss: 1.8090 - val_sparse_categorical_accuracy: 0.3626\n",
      "Epoch 49/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.7154 - sparse_categorical_accuracy: 0.4027 - val_loss: 1.7972 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 50/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.7388 - sparse_categorical_accuracy: 0.3970 - val_loss: 1.8508 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 51/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.7216 - sparse_categorical_accuracy: 0.3961 - val_loss: 1.8196 - val_sparse_categorical_accuracy: 0.3692\n",
      "Epoch 52/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.6888 - sparse_categorical_accuracy: 0.4093 - val_loss: 1.8543 - val_sparse_categorical_accuracy: 0.3538\n",
      "Epoch 53/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.6927 - sparse_categorical_accuracy: 0.4143 - val_loss: 1.8068 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 54/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.6935 - sparse_categorical_accuracy: 0.4139 - val_loss: 1.8616 - val_sparse_categorical_accuracy: 0.3516\n",
      "Epoch 55/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.6890 - sparse_categorical_accuracy: 0.4094 - val_loss: 1.8104 - val_sparse_categorical_accuracy: 0.3794\n",
      "Epoch 56/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.6833 - sparse_categorical_accuracy: 0.4058 - val_loss: 1.7988 - val_sparse_categorical_accuracy: 0.3808\n",
      "Epoch 57/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.7062 - sparse_categorical_accuracy: 0.3971 - val_loss: 1.8253 - val_sparse_categorical_accuracy: 0.3648\n",
      "Epoch 58/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.6548 - sparse_categorical_accuracy: 0.4154 - val_loss: 1.8427 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 59/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.6616 - sparse_categorical_accuracy: 0.4263 - val_loss: 1.8381 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 60/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.6458 - sparse_categorical_accuracy: 0.4112 - val_loss: 1.8368 - val_sparse_categorical_accuracy: 0.3699\n",
      "Epoch 61/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.6311 - sparse_categorical_accuracy: 0.4336 - val_loss: 1.8224 - val_sparse_categorical_accuracy: 0.3648\n",
      "Epoch 62/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.6398 - sparse_categorical_accuracy: 0.4272 - val_loss: 1.8142 - val_sparse_categorical_accuracy: 0.3779\n",
      "Epoch 63/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.6181 - sparse_categorical_accuracy: 0.4352 - val_loss: 1.7937 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 64/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.6402 - sparse_categorical_accuracy: 0.4274 - val_loss: 1.8038 - val_sparse_categorical_accuracy: 0.3721\n",
      "Epoch 65/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.6597 - sparse_categorical_accuracy: 0.4115 - val_loss: 1.8201 - val_sparse_categorical_accuracy: 0.3611\n",
      "Epoch 66/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.6332 - sparse_categorical_accuracy: 0.4317 - val_loss: 1.7880 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 67/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.6445 - sparse_categorical_accuracy: 0.4239 - val_loss: 1.8065 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 68/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.6157 - sparse_categorical_accuracy: 0.4146 - val_loss: 1.8289 - val_sparse_categorical_accuracy: 0.3472\n",
      "Epoch 69/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.5935 - sparse_categorical_accuracy: 0.4275 - val_loss: 1.8248 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 70/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.6061 - sparse_categorical_accuracy: 0.4301 - val_loss: 1.8281 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 71/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.6405 - sparse_categorical_accuracy: 0.4161 - val_loss: 1.8030 - val_sparse_categorical_accuracy: 0.3655\n",
      "Epoch 72/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 1.6071 - sparse_categorical_accuracy: 0.4312 - val_loss: 1.8388 - val_sparse_categorical_accuracy: 0.3662\n",
      "Epoch 73/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5974 - sparse_categorical_accuracy: 0.4381 - val_loss: 1.8350 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 74/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5606 - sparse_categorical_accuracy: 0.4389 - val_loss: 1.8552 - val_sparse_categorical_accuracy: 0.3743\n",
      "Epoch 75/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 1.5694 - sparse_categorical_accuracy: 0.4376 - val_loss: 1.8293 - val_sparse_categorical_accuracy: 0.3757\n",
      "Epoch 76/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.5849 - sparse_categorical_accuracy: 0.4459 - val_loss: 1.8506 - val_sparse_categorical_accuracy: 0.3480\n",
      "Epoch 77/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.5695 - sparse_categorical_accuracy: 0.4363 - val_loss: 1.8287 - val_sparse_categorical_accuracy: 0.3692\n",
      "Epoch 78/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 1.5856 - sparse_categorical_accuracy: 0.4213 - val_loss: 1.8554 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 79/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.5965 - sparse_categorical_accuracy: 0.4251 - val_loss: 1.8140 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 80/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.5609 - sparse_categorical_accuracy: 0.4484 - val_loss: 1.7960 - val_sparse_categorical_accuracy: 0.3706\n",
      "Epoch 81/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.5913 - sparse_categorical_accuracy: 0.4355 - val_loss: 1.8351 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 82/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 1.5664 - sparse_categorical_accuracy: 0.4423 - val_loss: 1.8174 - val_sparse_categorical_accuracy: 0.3596\n",
      "Epoch 83/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.5525 - sparse_categorical_accuracy: 0.4367 - val_loss: 1.8242 - val_sparse_categorical_accuracy: 0.3757\n",
      "Epoch 84/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.5689 - sparse_categorical_accuracy: 0.4374 - val_loss: 1.8321 - val_sparse_categorical_accuracy: 0.3611\n",
      "Epoch 85/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 1.5706 - sparse_categorical_accuracy: 0.4461 - val_loss: 1.8647 - val_sparse_categorical_accuracy: 0.3428\n",
      "Epoch 86/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.6119 - sparse_categorical_accuracy: 0.4260 - val_loss: 1.8431 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 87/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 1.5554 - sparse_categorical_accuracy: 0.4427 - val_loss: 1.8269 - val_sparse_categorical_accuracy: 0.3662\n",
      "Epoch 88/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.5179 - sparse_categorical_accuracy: 0.4598 - val_loss: 1.8679 - val_sparse_categorical_accuracy: 0.3501\n",
      "Epoch 89/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.5586 - sparse_categorical_accuracy: 0.4352 - val_loss: 1.8602 - val_sparse_categorical_accuracy: 0.3589\n",
      "Epoch 90/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.5597 - sparse_categorical_accuracy: 0.4378 - val_loss: 1.8818 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 91/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.5373 - sparse_categorical_accuracy: 0.4470 - val_loss: 1.8545 - val_sparse_categorical_accuracy: 0.3560\n",
      "Epoch 92/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.5171 - sparse_categorical_accuracy: 0.4559 - val_loss: 1.8574 - val_sparse_categorical_accuracy: 0.3684\n",
      "Epoch 93/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5440 - sparse_categorical_accuracy: 0.4389 - val_loss: 1.8538 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 94/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.5364 - sparse_categorical_accuracy: 0.4456 - val_loss: 1.8155 - val_sparse_categorical_accuracy: 0.3633\n",
      "Epoch 95/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.5547 - sparse_categorical_accuracy: 0.4355 - val_loss: 1.8375 - val_sparse_categorical_accuracy: 0.3728\n",
      "Epoch 96/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.5334 - sparse_categorical_accuracy: 0.4441 - val_loss: 1.8402 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 97/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5545 - sparse_categorical_accuracy: 0.4274 - val_loss: 1.8755 - val_sparse_categorical_accuracy: 0.3567\n",
      "Epoch 98/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.5331 - sparse_categorical_accuracy: 0.4488 - val_loss: 1.8434 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 99/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.5083 - sparse_categorical_accuracy: 0.4605 - val_loss: 1.8419 - val_sparse_categorical_accuracy: 0.3611\n",
      "Epoch 100/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.5132 - sparse_categorical_accuracy: 0.4587 - val_loss: 1.8389 - val_sparse_categorical_accuracy: 0.3874\n",
      "Epoch 101/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5396 - sparse_categorical_accuracy: 0.4490 - val_loss: 1.8122 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 102/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.5487 - sparse_categorical_accuracy: 0.4307 - val_loss: 1.8745 - val_sparse_categorical_accuracy: 0.3662\n",
      "Epoch 103/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.5136 - sparse_categorical_accuracy: 0.4550 - val_loss: 1.8495 - val_sparse_categorical_accuracy: 0.3648\n",
      "Epoch 104/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5151 - sparse_categorical_accuracy: 0.4470 - val_loss: 1.8618 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 105/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.5036 - sparse_categorical_accuracy: 0.4500 - val_loss: 1.8796 - val_sparse_categorical_accuracy: 0.3706\n",
      "Epoch 106/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.5262 - sparse_categorical_accuracy: 0.4596 - val_loss: 1.8816 - val_sparse_categorical_accuracy: 0.3640\n",
      "Epoch 107/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.5170 - sparse_categorical_accuracy: 0.4438 - val_loss: 1.8647 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 108/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.4949 - sparse_categorical_accuracy: 0.4546 - val_loss: 1.8833 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 109/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4979 - sparse_categorical_accuracy: 0.4600 - val_loss: 1.8539 - val_sparse_categorical_accuracy: 0.3779\n",
      "Epoch 110/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4553 - sparse_categorical_accuracy: 0.4737 - val_loss: 1.8629 - val_sparse_categorical_accuracy: 0.3779\n",
      "Epoch 111/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 1.5028 - sparse_categorical_accuracy: 0.4558 - val_loss: 1.9137 - val_sparse_categorical_accuracy: 0.3706\n",
      "Epoch 112/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4997 - sparse_categorical_accuracy: 0.4459 - val_loss: 1.9214 - val_sparse_categorical_accuracy: 0.3655\n",
      "Epoch 113/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.5007 - sparse_categorical_accuracy: 0.4647 - val_loss: 1.8664 - val_sparse_categorical_accuracy: 0.3706\n",
      "Epoch 114/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 1.4929 - sparse_categorical_accuracy: 0.4551 - val_loss: 1.8649 - val_sparse_categorical_accuracy: 0.3596\n",
      "Epoch 115/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.4708 - sparse_categorical_accuracy: 0.4622 - val_loss: 1.8917 - val_sparse_categorical_accuracy: 0.3721\n",
      "Epoch 116/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 1.5029 - sparse_categorical_accuracy: 0.4622 - val_loss: 1.9033 - val_sparse_categorical_accuracy: 0.3553\n",
      "Epoch 117/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.4876 - sparse_categorical_accuracy: 0.4639 - val_loss: 1.8753 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 118/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4823 - sparse_categorical_accuracy: 0.4710 - val_loss: 1.8862 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 119/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4824 - sparse_categorical_accuracy: 0.4741 - val_loss: 1.8983 - val_sparse_categorical_accuracy: 0.3655\n",
      "Epoch 120/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 1.4624 - sparse_categorical_accuracy: 0.4671 - val_loss: 1.8538 - val_sparse_categorical_accuracy: 0.3611\n",
      "Epoch 121/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4640 - sparse_categorical_accuracy: 0.4673 - val_loss: 1.8996 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 122/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4683 - sparse_categorical_accuracy: 0.4658 - val_loss: 1.9282 - val_sparse_categorical_accuracy: 0.3838\n",
      "Epoch 123/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.5038 - sparse_categorical_accuracy: 0.4484 - val_loss: 1.8635 - val_sparse_categorical_accuracy: 0.3692\n",
      "Epoch 124/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.4814 - sparse_categorical_accuracy: 0.4709 - val_loss: 1.9175 - val_sparse_categorical_accuracy: 0.3692\n",
      "Epoch 125/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 1.4582 - sparse_categorical_accuracy: 0.4723 - val_loss: 1.9486 - val_sparse_categorical_accuracy: 0.3706\n",
      "Epoch 126/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4917 - sparse_categorical_accuracy: 0.4583 - val_loss: 1.8992 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 127/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4782 - sparse_categorical_accuracy: 0.4562 - val_loss: 1.9022 - val_sparse_categorical_accuracy: 0.3582\n",
      "Epoch 128/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4668 - sparse_categorical_accuracy: 0.4581 - val_loss: 1.8769 - val_sparse_categorical_accuracy: 0.3757\n",
      "Epoch 129/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4563 - sparse_categorical_accuracy: 0.4717 - val_loss: 1.9229 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 130/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.4289 - sparse_categorical_accuracy: 0.4790 - val_loss: 1.9166 - val_sparse_categorical_accuracy: 0.3750\n",
      "Epoch 131/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4514 - sparse_categorical_accuracy: 0.4761 - val_loss: 1.8651 - val_sparse_categorical_accuracy: 0.3735\n",
      "Epoch 132/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.4573 - sparse_categorical_accuracy: 0.4627 - val_loss: 1.8999 - val_sparse_categorical_accuracy: 0.3575\n",
      "Epoch 133/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 1.4687 - sparse_categorical_accuracy: 0.4771 - val_loss: 1.9061 - val_sparse_categorical_accuracy: 0.3706\n",
      "Epoch 134/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 1.4801 - sparse_categorical_accuracy: 0.4798 - val_loss: 1.8733 - val_sparse_categorical_accuracy: 0.3604\n",
      "Epoch 135/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 1.4435 - sparse_categorical_accuracy: 0.4731 - val_loss: 1.9045 - val_sparse_categorical_accuracy: 0.3626\n",
      "Epoch 136/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 1.4451 - sparse_categorical_accuracy: 0.4688 - val_loss: 1.8889 - val_sparse_categorical_accuracy: 0.3721\n",
      "Epoch 137/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 1.4545 - sparse_categorical_accuracy: 0.4597 - val_loss: 1.8871 - val_sparse_categorical_accuracy: 0.3648\n",
      "Epoch 138/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 1.4696 - sparse_categorical_accuracy: 0.4882 - val_loss: 1.9235 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 139/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.4518 - sparse_categorical_accuracy: 0.4692 - val_loss: 1.8815 - val_sparse_categorical_accuracy: 0.3699\n",
      "Epoch 140/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.4553 - sparse_categorical_accuracy: 0.4606 - val_loss: 1.8862 - val_sparse_categorical_accuracy: 0.3779\n",
      "Epoch 141/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4223 - sparse_categorical_accuracy: 0.4726 - val_loss: 1.9160 - val_sparse_categorical_accuracy: 0.3618\n",
      "Epoch 142/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4388 - sparse_categorical_accuracy: 0.4919 - val_loss: 1.9412 - val_sparse_categorical_accuracy: 0.3684\n",
      "Epoch 143/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 1.4748 - sparse_categorical_accuracy: 0.4690 - val_loss: 1.9602 - val_sparse_categorical_accuracy: 0.3655\n",
      "Epoch 144/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 1.4299 - sparse_categorical_accuracy: 0.4804 - val_loss: 1.9366 - val_sparse_categorical_accuracy: 0.3487\n",
      "Epoch 145/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 1.4026 - sparse_categorical_accuracy: 0.4987 - val_loss: 1.9156 - val_sparse_categorical_accuracy: 0.3750\n",
      "Epoch 146/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.4698 - sparse_categorical_accuracy: 0.4637 - val_loss: 1.9257 - val_sparse_categorical_accuracy: 0.3677\n",
      "Epoch 147/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.4167 - sparse_categorical_accuracy: 0.4731 - val_loss: 1.9109 - val_sparse_categorical_accuracy: 0.3626\n",
      "Epoch 148/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 1.4898 - sparse_categorical_accuracy: 0.4463 - val_loss: 1.9602 - val_sparse_categorical_accuracy: 0.3670\n",
      "Epoch 149/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 1.3981 - sparse_categorical_accuracy: 0.4880 - val_loss: 1.8848 - val_sparse_categorical_accuracy: 0.3787\n",
      "Epoch 150/150\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 1.4227 - sparse_categorical_accuracy: 0.4774 - val_loss: 1.9074 - val_sparse_categorical_accuracy: 0.3765\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_seq_RA, y_train_seq_RA, epochs=150, batch_size =64, validation_split=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e7023e-23f4-4fb9-bed9-fbe7349af410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
